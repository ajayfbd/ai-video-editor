"""
AI Director - Core intelligence module for creative and strategic video editing decisions.

This module implements the AI Director that acts as a professional video editor,
content strategist, and SEO specialist, making nuanced decisions about editing,
B-roll, and metadata generation based on comprehensive content analysis.
"""

import json
import logging
import asyncio
import time
from typing import Dict, List, Optional, Any, Union, AsyncGenerator, Callable
from datetime import datetime
from dataclasses import dataclass, asdict

from .gemini_client import GeminiClient, GeminiConfig, GeminiResponse
from ...core.content_context import ContentContext, ContentType, EmotionalPeak, VisualHighlight
from ...core.exceptions import (
    GeminiAPIError, 
    ContentContextError, 
    ProcessingTimeoutError,
    handle_errors
)


logger = logging.getLogger(__name__)


@dataclass
class EditingDecision:
    """Represents a single editing decision made by the AI Director."""
    timestamp: float
    decision_type: str  # "cut", "trim", "transition", "emphasis", "b_roll"
    parameters: Dict[str, Any]
    rationale: str
    confidence: float
    priority: int  # 1-10, higher is more important
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'EditingDecision':
        return cls(**data)


@dataclass
class BRollPlan:
    """Represents a B-roll insertion plan."""
    timestamp: float
    duration: float
    content_type: str  # "chart", "animation", "slide", "graphic"
    description: str
    visual_elements: List[str]
    animation_style: str
    priority: int
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'BRollPlan':
        return cls(**data)


@dataclass
class MetadataStrategy:
    """Represents SEO and metadata strategy."""
    primary_title: str
    title_variations: List[str]
    description: str
    tags: List[str]
    thumbnail_concepts: List[str]
    hook_text: str
    target_keywords: List[str]
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'MetadataStrategy':
        return cls(**data)


@dataclass
class AIDirectorPlan:
    """Complete plan generated by the AI Director."""
    editing_decisions: List[EditingDecision]
    broll_plans: List[BRollPlan]
    metadata_strategy: MetadataStrategy
    quality_enhancements: List[str]
    pacing_adjustments: List[Dict[str, Any]]
    engagement_hooks: List[Dict[str, Any]]
    
    # Metadata
    created_at: datetime
    confidence_score: float
    processing_time: float
    model_used: str
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'editing_decisions': [decision.to_dict() for decision in self.editing_decisions],
            'broll_plans': [plan.to_dict() for plan in self.broll_plans],
            'metadata_strategy': self.metadata_strategy.to_dict(),
            'quality_enhancements': self.quality_enhancements,
            'pacing_adjustments': self.pacing_adjustments,
            'engagement_hooks': self.engagement_hooks,
            'created_at': self.created_at.isoformat(),
            'confidence_score': self.confidence_score,
            'processing_time': self.processing_time,
            'model_used': self.model_used
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'AIDirectorPlan':
        editing_decisions = [EditingDecision.from_dict(d) for d in data['editing_decisions']]
        broll_plans = [BRollPlan.from_dict(p) for p in data['broll_plans']]
        metadata_strategy = MetadataStrategy.from_dict(data['metadata_strategy'])
        
        return cls(
            editing_decisions=editing_decisions,
            broll_plans=broll_plans,
            metadata_strategy=metadata_strategy,
            quality_enhancements=data['quality_enhancements'],
            pacing_adjustments=data['pacing_adjustments'],
            engagement_hooks=data['engagement_hooks'],
            created_at=datetime.fromisoformat(data['created_at']),
            confidence_score=data['confidence_score'],
            processing_time=data['processing_time'],
            model_used=data['model_used']
        )


class FinancialVideoEditor:
    """
    AI Director specialized in financial educational content.
    
    This class acts as a professional video editor with expertise in financial
    education, making intelligent decisions about editing, B-roll placement,
    and metadata optimization for maximum engagement and educational value.
    """
    
    def __init__(
        self,
        gemini_client: GeminiClient,
        quality_focused: bool = True,
        streaming_enabled: bool = True,
        max_processing_time: float = 300.0
    ):
        """
        Initialize the Financial Video Editor.
        
        Args:
            gemini_client: Configured GeminiClient instance
            quality_focused: Prioritize quality over cost optimization
            streaming_enabled: Enable streaming responses for real-time feedback
            max_processing_time: Maximum processing time in seconds
        """
        self.gemini_client = gemini_client
        self.quality_focused = quality_focused
        self.streaming_enabled = streaming_enabled
        self.max_processing_time = max_processing_time
        
        # Financial content specialization
        self.financial_keywords = [
            'investment', 'portfolio', 'stocks', 'bonds', 'returns', 'risk',
            'diversification', 'compound interest', 'inflation', 'budgeting',
            'savings', 'debt', 'credit', 'retirement', 'taxes', 'financial planning',
            'asset allocation', 'market volatility', 'dividend', 'capital gains'
        ]
        
        # Editing strategies for financial content
        self.retention_techniques = {
            'hook_placement': 'Every 30-45 seconds',
            'concept_reinforcement': 'Repeat key points 3 times',
            'visual_aids': 'Charts/graphs for data points',
            'pacing': 'Slower for complex concepts',
            'engagement_hooks': 'Questions and scenarios'
        }
        
        logger.info(f"FinancialVideoEditor initialized with quality_focused={quality_focused}")
    
    @handle_errors()
    def create_financial_editing_prompt(self, context: ContentContext) -> str:
        """
        Create specialized prompt for financial educational content editing.
        
        Args:
            context: ContentContext with analyzed content data
            
        Returns:
            Comprehensive prompt for AI Director decisions
        """
        # Extract key information from context
        transcript_summary = self._extract_transcript_summary(context)
        key_concepts = self._extract_key_concepts(context)
        emotional_peaks = self._extract_emotional_peaks(context)
        visual_highlights = self._extract_visual_highlights(context)
        
        prompt = f"""
You are a professional video editor and content strategist specializing in financial educational content. 
Your goal is to create a comprehensive editing plan that maximizes engagement, retention, and educational value.

CONTENT ANALYSIS:
- Content Type: {context.content_type.value}
- Duration: {getattr(context, 'total_duration', 'Unknown')} seconds
- Key Concepts: {', '.join(key_concepts[:10])}
- Emotional Peaks: {len(emotional_peaks)} identified
- Visual Highlights: {len(visual_highlights)} identified

TRANSCRIPT SUMMARY:
{transcript_summary}

FINANCIAL EDUCATION EDITING REQUIREMENTS:
1. ENGAGEMENT STRATEGY: Place hooks every 30-45 seconds to maintain attention
2. CONCEPT REINFORCEMENT: Identify opportunities to reinforce key financial concepts
3. VISUAL INTEGRATION: Suggest where charts, graphs, or visual aids are needed
4. PACING CONTROL: Slower pacing for complex financial concepts, faster for examples
5. RETENTION OPTIMIZATION: Strategic pauses and emphasis for key information
6. EDUCATIONAL FLOW: Ensure logical progression of financial concepts

QUALITY FOCUS: Prioritize educational value and professional polish over cost optimization.

Please provide a comprehensive editing plan in JSON format with the following structure:
{{
    "editing_decisions": [
        {{
            "timestamp": 0.0,
            "decision_type": "cut|trim|transition|emphasis|b_roll",
            "parameters": {{"specific_parameters": "value"}},
            "rationale": "Why this decision improves the content",
            "confidence": 0.95,
            "priority": 8
        }}
    ],
    "broll_plans": [
        {{
            "timestamp": 0.0,
            "duration": 5.0,
            "content_type": "chart|animation|slide|graphic",
            "description": "What visual aid to create",
            "visual_elements": ["element1", "element2"],
            "animation_style": "fade_in|slide_up|zoom",
            "priority": 7
        }}
    ],
    "metadata_strategy": {{
        "primary_title": "Engaging YouTube title",
        "title_variations": ["Alternative title 1", "Alternative title 2"],
        "description": "SEO-optimized description with timestamps",
        "tags": ["tag1", "tag2", "tag3"],
        "thumbnail_concepts": ["concept1", "concept2"],
        "hook_text": "Compelling hook for thumbnail",
        "target_keywords": ["keyword1", "keyword2"]
    }},
    "quality_enhancements": [
        "Audio cleanup at 1:23-1:45",
        "Color correction for better lighting"
    ],
    "pacing_adjustments": [
        {{
            "timestamp": 0.0,
            "adjustment": "slow_down|speed_up|pause",
            "duration": 2.0,
            "reason": "Complex concept explanation"
        }}
    ],
    "engagement_hooks": [
        {{
            "timestamp": 30.0,
            "type": "question|statistic|scenario",
            "content": "Hook content",
            "visual_treatment": "text_overlay|graphic|animation"
        }}
    ]
}}

Focus on creating a cohesive, professional, and highly engaging financial education video.
"""
        
        return prompt
    
    def _extract_transcript_summary(self, context: ContentContext) -> str:
        """Extract and summarize transcript from context."""
        if hasattr(context, 'audio_transcript') and context.audio_transcript:
            # Get first 500 characters as summary
            full_text = context.audio_transcript.text if hasattr(context.audio_transcript, 'text') else str(context.audio_transcript)
            return full_text[:500] + "..." if len(full_text) > 500 else full_text
        return "No transcript available"
    
    def _extract_key_concepts(self, context: ContentContext) -> List[str]:
        """Extract key financial concepts from context."""
        concepts = []
        
        # From key_concepts if available
        if hasattr(context, 'key_concepts') and context.key_concepts:
            concepts.extend(context.key_concepts[:5])
        
        # From financial keywords in transcript
        if hasattr(context, 'audio_transcript') and context.audio_transcript:
            transcript_text = getattr(context.audio_transcript, 'text', str(context.audio_transcript)).lower()
            for keyword in self.financial_keywords:
                if keyword.lower() in transcript_text and keyword not in concepts:
                    concepts.append(keyword)
                    if len(concepts) >= 10:
                        break
        
        return concepts or ['financial education', 'investment basics']
    
    def _extract_emotional_peaks(self, context: ContentContext) -> List[EmotionalPeak]:
        """Extract emotional peaks from context."""
        if hasattr(context, 'emotional_markers') and context.emotional_markers:
            return context.emotional_markers
        return []
    
    def _extract_visual_highlights(self, context: ContentContext) -> List[VisualHighlight]:
        """Extract visual highlights from context."""
        if hasattr(context, 'visual_highlights') and context.visual_highlights:
            return context.visual_highlights
        return []
    
    @handle_errors()
    async def generate_editing_plan(
        self,
        context: ContentContext,
        streaming: Optional[bool] = None
    ) -> AIDirectorPlan:
        """
        Generate comprehensive editing plan using AI Director.
        
        Args:
            context: ContentContext with analyzed content
            streaming: Enable streaming responses (overrides default)
            
        Returns:
            AIDirectorPlan with all editing decisions
            
        Raises:
            GeminiAPIError: If AI Director analysis fails
            ContentContextError: If context is invalid
        """
        start_time = time.time()
        use_streaming = streaming if streaming is not None else self.streaming_enabled
        
        try:
            # Validate context
            if not context:
                raise ContentContextError("Invalid ContentContext provided")
            
            # Create specialized prompt
            prompt = self.create_financial_editing_prompt(context)
            
            # Define response schema for structured output
            response_schema = {
                "type": "object",
                "required": ["editing_decisions", "broll_plans", "metadata_strategy"],
                "properties": {
                    "editing_decisions": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "required": ["timestamp", "decision_type", "rationale", "confidence", "priority"]
                        }
                    },
                    "broll_plans": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "required": ["timestamp", "duration", "content_type", "description"]
                        }
                    },
                    "metadata_strategy": {
                        "type": "object",
                        "required": ["primary_title", "description", "tags"]
                    }
                }
            }
            
            # Configure for quality-focused processing
            config = GeminiConfig(
                model="gemini-2.5-pro-latest" if self.quality_focused else "gemini-2.0-flash-exp",
                temperature=0.7,
                top_p=0.9,
                max_output_tokens=4000
            )
            
            # System instruction for financial content expertise
            system_instruction = """
You are an expert video editor specializing in financial educational content. 
You understand the importance of clear explanations, visual aids for complex concepts, 
and maintaining viewer engagement throughout educational videos. Always prioritize 
educational value and professional quality in your editing decisions.
"""
            
            logger.info("Generating AI Director editing plan...")
            
            # Generate structured response with optional streaming
            if use_streaming:
                logger.info("Using streaming response for real-time feedback")
                response_data = await self._generate_streaming_response(
                    prompt=prompt,
                    response_schema=response_schema,
                    config=config,
                    system_instruction=system_instruction,
                    context=context
                )
            else:
                response_data = self.gemini_client.generate_structured_response(
                    prompt=prompt,
                    response_schema=response_schema,
                    config=config,
                    system_instruction=system_instruction,
                    context=context,
                    max_attempts=3
                )
            
            # Parse response into structured plan
            editing_plan = self._parse_editing_response(response_data, start_time, config.model)
            
            # Store plan in context
            context.ai_director_plan = editing_plan
            
            # Update processing metrics
            processing_time = time.time() - start_time
            context.processing_metrics.add_module_processing_time('ai_director', processing_time)
            
            logger.info(f"AI Director plan generated successfully in {processing_time:.2f}s")
            logger.info(f"Plan includes {len(editing_plan.editing_decisions)} editing decisions, "
                       f"{len(editing_plan.broll_plans)} B-roll plans")
            
            return editing_plan
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"Failed to generate editing plan after {processing_time:.2f}s: {str(e)}")
            
            if isinstance(e, (GeminiAPIError, ContentContextError)):
                raise
            
            raise GeminiAPIError(
                "editing_plan_generation",
                reason=f"Unexpected error in editing plan generation: {str(e)}",
                details={"processing_time": processing_time, "error_type": type(e).__name__}
            )
    
    def _parse_editing_response(self, response_data: Dict[str, Any], start_time: float, model_used: str) -> AIDirectorPlan:
        """
        Parse AI response into structured AIDirectorPlan.
        
        Args:
            response_data: Parsed JSON response from AI
            start_time: Processing start time
            model_used: Model used for generation
            
        Returns:
            AIDirectorPlan with parsed data
        """
        try:
            # Parse editing decisions
            editing_decisions = []
            for decision_data in response_data.get('editing_decisions', []):
                decision = EditingDecision(
                    timestamp=float(decision_data.get('timestamp', 0.0)),
                    decision_type=decision_data.get('decision_type', 'cut'),
                    parameters=decision_data.get('parameters', {}),
                    rationale=decision_data.get('rationale', ''),
                    confidence=float(decision_data.get('confidence', 0.8)),
                    priority=int(decision_data.get('priority', 5))
                )
                editing_decisions.append(decision)
            
            # Parse B-roll plans
            broll_plans = []
            for broll_data in response_data.get('broll_plans', []):
                broll_plan = BRollPlan(
                    timestamp=float(broll_data.get('timestamp', 0.0)),
                    duration=float(broll_data.get('duration', 5.0)),
                    content_type=broll_data.get('content_type', 'graphic'),
                    description=broll_data.get('description', ''),
                    visual_elements=broll_data.get('visual_elements', []),
                    animation_style=broll_data.get('animation_style', 'fade_in'),
                    priority=int(broll_data.get('priority', 5))
                )
                broll_plans.append(broll_plan)
            
            # Parse metadata strategy
            metadata_data = response_data.get('metadata_strategy', {})
            metadata_strategy = MetadataStrategy(
                primary_title=metadata_data.get('primary_title', 'Financial Education Video'),
                title_variations=metadata_data.get('title_variations', []),
                description=metadata_data.get('description', ''),
                tags=metadata_data.get('tags', []),
                thumbnail_concepts=metadata_data.get('thumbnail_concepts', []),
                hook_text=metadata_data.get('hook_text', ''),
                target_keywords=metadata_data.get('target_keywords', [])
            )
            
            # Calculate confidence score
            confidence_scores = [d.confidence for d in editing_decisions]
            overall_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.8
            
            # Create complete plan
            plan = AIDirectorPlan(
                editing_decisions=editing_decisions,
                broll_plans=broll_plans,
                metadata_strategy=metadata_strategy,
                quality_enhancements=response_data.get('quality_enhancements', []),
                pacing_adjustments=response_data.get('pacing_adjustments', []),
                engagement_hooks=response_data.get('engagement_hooks', []),
                created_at=datetime.now(),
                confidence_score=overall_confidence,
                processing_time=time.time() - start_time,
                model_used=model_used
            )
            
            return plan
            
        except Exception as e:
            logger.error(f"Failed to parse editing response: {str(e)}")
            raise ContentContextError(
                f"Failed to parse AI Director response: {str(e)}",
                context_state=None
            )
    
    @handle_errors()
    def analyze_content_for_broll(self, context: ContentContext) -> List[Dict[str, Any]]:
        """
        Analyze content to identify B-roll opportunities.
        
        Args:
            context: ContentContext with transcript and analysis
            
        Returns:
            List of B-roll opportunities with timing and type
        """
        opportunities = []
        
        # Analyze transcript for visual triggers
        if hasattr(context, 'audio_transcript') and context.audio_transcript:
            transcript_segments = getattr(context.audio_transcript, 'segments', [])
            
            for segment in transcript_segments:
                text = getattr(segment, 'text', str(segment)).lower()
                timestamp = getattr(segment, 'start', 0.0)
                duration = getattr(segment, 'end', timestamp + 5.0) - timestamp
                
                # Check for chart/data keywords
                chart_keywords = ['percent', 'percentage', 'growth', 'decline', 'chart', 'graph', 'data', 'statistics']
                if any(keyword in text for keyword in chart_keywords):
                    opportunities.append({
                        'type': 'data_visualization',
                        'timestamp': timestamp,
                        'duration': min(duration, 8.0),
                        'content': text,
                        'priority': 8,
                        'visual_type': 'chart_or_graph'
                    })
                
                # Check for concept explanation keywords
                concept_keywords = ['compound interest', 'diversification', 'portfolio', 'risk', 'return', 'investment']
                if any(keyword in text for keyword in concept_keywords):
                    opportunities.append({
                        'type': 'concept_explanation',
                        'timestamp': timestamp,
                        'duration': min(duration, 10.0),
                        'content': text,
                        'priority': 7,
                        'visual_type': 'animated_explanation'
                    })
                
                # Check for process explanation keywords
                process_keywords = ['steps', 'process', 'how to', 'method', 'strategy', 'calculate']
                if any(keyword in text for keyword in process_keywords):
                    opportunities.append({
                        'type': 'process_diagram',
                        'timestamp': timestamp,
                        'duration': min(duration, 12.0),
                        'content': text,
                        'priority': 6,
                        'visual_type': 'step_by_step_visual'
                    })
        
        # Sort by priority and timestamp
        opportunities.sort(key=lambda x: (-x['priority'], x['timestamp']))
        
        logger.info(f"Identified {len(opportunities)} B-roll opportunities")
        return opportunities
    
    async def _generate_streaming_response(
        self,
        prompt: str,
        response_schema: Dict[str, Any],
        config: GeminiConfig,
        system_instruction: str,
        context: ContentContext
    ) -> Dict[str, Any]:
        """
        Generate streaming response for real-time feedback.
        
        Args:
            prompt: Input prompt
            response_schema: JSON schema for response validation
            config: Request configuration
            system_instruction: System instruction
            context: ContentContext for tracking
            
        Returns:
            Parsed JSON response data
            
        Raises:
            GeminiAPIError: If streaming response fails
        """
        try:
            logger.info("Starting streaming response generation...")
            
            # For now, we'll simulate streaming by providing progress updates
            # In a full implementation, this would use the Gemini streaming API
            
            # Phase 1: Content Analysis
            logger.info("Streaming: Analyzing content structure...")
            await asyncio.sleep(0.1)  # Simulate processing time
            
            # Phase 2: Editing Decisions
            logger.info("Streaming: Generating editing decisions...")
            await asyncio.sleep(0.2)
            
            # Phase 3: B-roll Planning
            logger.info("Streaming: Planning B-roll insertions...")
            await asyncio.sleep(0.2)
            
            # Phase 4: Metadata Strategy
            logger.info("Streaming: Creating metadata strategy...")
            await asyncio.sleep(0.2)
            
            # Phase 5: Final Assembly
            logger.info("Streaming: Assembling final plan...")
            await asyncio.sleep(0.1)
            
            # Generate the actual response using the standard method
            # In a real streaming implementation, this would be built incrementally
            response_data = self.gemini_client.generate_structured_response(
                prompt=prompt,
                response_schema=response_schema,
                config=config,
                system_instruction=system_instruction,
                context=context,
                max_attempts=3
            )
            
            logger.info("Streaming response generation completed")
            return response_data
            
        except Exception as e:
            logger.error(f"Streaming response generation failed: {str(e)}")
            raise GeminiAPIError(
                "streaming_response",
                reason=f"Streaming response failed: {str(e)}",
                details={"error_type": type(e).__name__}
            )
    
    @handle_errors()
    def optimize_for_engagement(self, context: ContentContext) -> Dict[str, Any]:
        """
        Generate engagement optimization recommendations.
        
        Args:
            context: ContentContext with content analysis
            
        Returns:
            Dictionary with engagement optimization strategies
        """
        optimization_strategies = {
            'hook_placements': [],
            'retention_techniques': [],
            'pacing_adjustments': [],
            'visual_enhancements': []
        }
        
        # Analyze emotional peaks for hook placement
        emotional_peaks = self._extract_emotional_peaks(context)
        for peak in emotional_peaks:
            if hasattr(peak, 'timestamp'):
                optimization_strategies['hook_placements'].append({
                    'timestamp': peak.timestamp,
                    'type': 'emotional_hook',
                    'content': getattr(peak, 'description', 'Emotional peak'),
                    'treatment': 'emphasis_and_pause'
                })
        
        # Add regular engagement hooks every 30-45 seconds
        total_duration = getattr(context, 'total_duration', 180)  # Default 3 minutes
        hook_interval = 35  # seconds
        
        for timestamp in range(hook_interval, int(total_duration), hook_interval):
            optimization_strategies['hook_placements'].append({
                'timestamp': float(timestamp),
                'type': 'retention_hook',
                'content': 'Engagement question or teaser',
                'treatment': 'text_overlay_with_pause'
            })
        
        # Pacing recommendations based on content complexity
        key_concepts = self._extract_key_concepts(context)
        complex_concepts = ['compound interest', 'diversification', 'asset allocation', 'risk management']
        
        for concept in key_concepts:
            if concept.lower() in [c.lower() for c in complex_concepts]:
                optimization_strategies['pacing_adjustments'].append({
                    'concept': concept,
                    'recommendation': 'slow_down',
                    'reason': 'Complex financial concept requires slower pacing'
                })
        
        return optimization_strategies
    
    async def generate_editing_plan_with_callback(
        self,
        context: ContentContext,
        progress_callback: Optional[Callable[[str, float], None]] = None,
        streaming: Optional[bool] = None
    ) -> AIDirectorPlan:
        """
        Generate editing plan with progress callback for real-time updates.
        
        Args:
            context: ContentContext with analyzed content
            progress_callback: Optional callback function for progress updates
            streaming: Enable streaming responses (overrides default)
            
        Returns:
            AIDirectorPlan with all editing decisions
            
        Raises:
            GeminiAPIError: If AI Director analysis fails
            ContentContextError: If context is invalid
        """
        if progress_callback:
            progress_callback("Starting AI Director analysis...", 0.0)
        
        try:
            # Use streaming if callback is provided or explicitly enabled
            use_streaming = streaming if streaming is not None else (
                self.streaming_enabled or progress_callback is not None
            )
            
            if progress_callback:
                progress_callback("Analyzing content structure...", 0.1)
            
            # Generate the plan with streaming support
            plan = await self.generate_editing_plan(context, streaming=use_streaming)
            
            if progress_callback:
                progress_callback("AI Director analysis completed", 1.0)
            
            return plan
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"Error: {str(e)}", -1.0)
            raise
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """
        Get processing statistics for the AI Director.
        
        Returns:
            Dictionary with processing metrics
        """
        return {
            'quality_focused': self.quality_focused,
            'streaming_enabled': self.streaming_enabled,
            'max_processing_time': self.max_processing_time,
            'financial_keywords_count': len(self.financial_keywords),
            'retention_techniques': self.retention_techniques,
            'gemini_client_stats': self.gemini_client.get_usage_stats() if self.gemini_client else {}
        }

# Utility functions for AI Director operations

def create_financial_video_editor(
    api_key: Optional[str] = None,
    cache_manager: Optional[Any] = None,
    quality_focused: bool = True,
    streaming_enabled: bool = True,
    max_processing_time: float = 300.0
) -> FinancialVideoEditor:
    """
    Factory function to create a configured FinancialVideoEditor.
    
    Args:
        api_key: Gemini API key (uses environment variable if None)
        cache_manager: CacheManager instance for response caching
        quality_focused: Prioritize quality over cost optimization
        streaming_enabled: Enable streaming responses
        max_processing_time: Maximum processing time in seconds
        
    Returns:
        Configured FinancialVideoEditor instance
        
    Raises:
        ConfigurationError: If configuration is invalid
    """
    try:
        # Create GeminiClient with configuration
        gemini_client = GeminiClient(
            api_key=api_key,
            cache_manager=cache_manager,
            enable_caching=True,
            cache_ttl=3600,  # 1 hour cache
            max_retries=3,
            timeout=120.0
        )
        
        # Create and return FinancialVideoEditor
        editor = FinancialVideoEditor(
            gemini_client=gemini_client,
            quality_focused=quality_focused,
            streaming_enabled=streaming_enabled,
            max_processing_time=max_processing_time
        )
        
        logger.info("FinancialVideoEditor created successfully")
        return editor
        
    except Exception as e:
        logger.error(f"Failed to create FinancialVideoEditor: {str(e)}")
        raise


def validate_editing_plan(plan: AIDirectorPlan) -> bool:
    """
    Validate that an editing plan is complete and consistent.
    
    Args:
        plan: AIDirectorPlan to validate
        
    Returns:
        True if plan is valid, False otherwise
    """
    try:
        # Check required components
        if not plan.editing_decisions:
            logger.warning("Editing plan has no editing decisions")
            return False
        
        if not plan.metadata_strategy:
            logger.warning("Editing plan has no metadata strategy")
            return False
        
        # Check timestamp consistency
        for decision in plan.editing_decisions:
            if decision.timestamp < 0:
                logger.warning(f"Invalid timestamp in editing decision: {decision.timestamp}")
                return False
        
        for broll_plan in plan.broll_plans:
            if broll_plan.timestamp < 0 or broll_plan.duration <= 0:
                logger.warning(f"Invalid B-roll timing: {broll_plan.timestamp}, {broll_plan.duration}")
                return False
        
        # Check confidence scores
        if plan.confidence_score < 0.5:
            logger.warning(f"Low confidence score in editing plan: {plan.confidence_score}")
            return False
        
        logger.debug("Editing plan validation passed")
        return True
        
    except Exception as e:
        logger.error(f"Error validating editing plan: {str(e)}")
        return False


def merge_editing_plans(plans: List[AIDirectorPlan]) -> AIDirectorPlan:
    """
    Merge multiple editing plans into a single comprehensive plan.
    
    Args:
        plans: List of AIDirectorPlan objects to merge
        
    Returns:
        Merged AIDirectorPlan
        
    Raises:
        ContentContextError: If plans cannot be merged
    """
    if not plans:
        raise ContentContextError("No plans provided for merging")
    
    if len(plans) == 1:
        return plans[0]
    
    try:
        # Merge editing decisions
        all_editing_decisions = []
        for plan in plans:
            all_editing_decisions.extend(plan.editing_decisions)
        
        # Sort by timestamp and priority
        all_editing_decisions.sort(key=lambda x: (x.timestamp, -x.priority))
        
        # Merge B-roll plans
        all_broll_plans = []
        for plan in plans:
            all_broll_plans.extend(plan.broll_plans)
        
        # Sort by timestamp and priority
        all_broll_plans.sort(key=lambda x: (x.timestamp, -x.priority))
        
        # Use metadata strategy from highest confidence plan
        best_plan = max(plans, key=lambda x: x.confidence_score)
        metadata_strategy = best_plan.metadata_strategy
        
        # Merge other components
        quality_enhancements = []
        pacing_adjustments = []
        engagement_hooks = []
        
        for plan in plans:
            quality_enhancements.extend(plan.quality_enhancements)
            pacing_adjustments.extend(plan.pacing_adjustments)
            engagement_hooks.extend(plan.engagement_hooks)
        
        # Calculate merged confidence score
        confidence_scores = [plan.confidence_score for plan in plans]
        merged_confidence = sum(confidence_scores) / len(confidence_scores)
        
        # Calculate total processing time
        total_processing_time = sum(plan.processing_time for plan in plans)
        
        # Create merged plan
        merged_plan = AIDirectorPlan(
            editing_decisions=all_editing_decisions,
            broll_plans=all_broll_plans,
            metadata_strategy=metadata_strategy,
            quality_enhancements=quality_enhancements,
            pacing_adjustments=pacing_adjustments,
            engagement_hooks=engagement_hooks,
            created_at=datetime.now(),
            confidence_score=merged_confidence,
            processing_time=total_processing_time,
            model_used=f"merged_from_{len(plans)}_plans"
        )
        
        logger.info(f"Successfully merged {len(plans)} editing plans")
        return merged_plan
        
    except Exception as e:
        logger.error(f"Failed to merge editing plans: {str(e)}")
        raise ContentContextError(f"Failed to merge editing plans: {str(e)}")


# Prompt templates for different content types
FINANCIAL_EDUCATION_PROMPTS = {
    'beginner': """
    Focus on clear, simple explanations with frequent visual aids.
    Use slower pacing and more repetition for key concepts.
    Include basic examples and avoid jargon.
    """,
    
    'intermediate': """
    Balance explanation with practical application.
    Include charts and data visualizations for key points.
    Use moderate pacing with strategic emphasis.
    """,
    
    'advanced': """
    Focus on nuanced analysis and complex relationships.
    Use data-heavy visualizations and detailed charts.
    Maintain professional pacing with technical depth.
    """
}


def get_content_level_prompt(content_level: str = 'intermediate') -> str:
    """
    Get specialized prompt based on content complexity level.
    
    Args:
        content_level: 'beginner', 'intermediate', or 'advanced'
        
    Returns:
        Specialized prompt text for the content level
    """
    return FINANCIAL_EDUCATION_PROMPTS.get(
        content_level.lower(), 
        FINANCIAL_EDUCATION_PROMPTS['intermediate']
    )